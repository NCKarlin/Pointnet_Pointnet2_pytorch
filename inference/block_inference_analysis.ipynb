{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Inference & Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook was designed to use an existing pre-trained model for the inference of a sample, and subsequently giving out some accuracy and summary statistics concerning the prediction. Therefore, the specific input data alongside the pre-trained model have to be loaded, before starting the inference on the input data provided here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports & Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'dataprepvenv' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n dataprepvenv ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# all needed packages/ libraries will be imported here, as well as any function definition, that might be useful/ needed for the execution of this notebook\n",
    "import os \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables to be set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_samples = os.path.dirname(os.path.abspath(__file__))\n",
    "print(path_to_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Inference Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will load in the input data, consisting of one entire sample. Then subsequently we will have to pre-process the data, so that it is in the same format as the training data for the model. Finally, wewill be left with the data to be inferenced. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Loading of example sample for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "1. option: load specified amount of blocks \n",
    "2. option load entire sample\n",
    "Create list of blocks to infer -> np.load with for-loop\n",
    "'''\n",
    "# creation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Pre-processing of Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Check the dataloader script about how to pre-process any of the input data to the actual data \n",
    "structure used in the model\n",
    "-> normalized coords/ colors, etc.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Loading in of trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to infer on the data provided, the model with its states (weights and biases) has to be loaded in and instantiated. Subsequently, we should be able to hand over the blocks, either collectively or individually for retrieving the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "- load the model \n",
    "- instantiate it with its states\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Inference of sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the loaded model, we will now pass the inputs to generate the outputs we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Generate outputs with loaded model and coresponding input\n",
    "#! Remember to adjust all formats for the predictions as in the training script\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Inference visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a first part we will visualize the results of the inference alongisde the ground truth. Through this we should get a good first indication on the success of the model. Nevertheless, more detailed statistics on the ifnerence will follow below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Create a plot with two subplots\n",
    "1. LEFT:\n",
    "- Original marked sample\n",
    "2. RIGHT:\n",
    "- Predictions from Inference colored accordingly\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Inference analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, after the inference and it's visualization, we will now continue onto the actual more detailed analysis of the prediction. With the results presented here, we should be able to evaluate the performance of the model conclusively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix and mIoU, etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pointnetnew",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
