{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# index_points function\n",
    "The index-points function is a central function within the overall model. At several stages within a single pass, the respective sampled points have to be selected and re-indexed for the next layer or function to process them. This notebook aims at specifically looking at this function with its respective inputs, as for the multi-scale-grouping (MSG) version of this model, currently we are receiving the following error: <br>\n",
    "<br>\n",
    "*RuntimeError: CUDA error: device-side assert triggered* <br>\n",
    "<br>\n",
    "This usually means, that there is something going sideways with the indices, I have found out. Therefore we will now adjust the function and test it in all its glory to finally get rid of this motherf****** error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Previous definition of index_points\n",
    "In order to evaluate the situation properly, I have inserted the commented and traditional verison of the function definition below. For clarity it has been renamed **index_points_old**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traditional definition of inddex_points\n",
    "def index_points_old(points, idx):\n",
    "    \"\"\"\n",
    "    Indexing points according to new group index.\n",
    "    \n",
    "    Input:\n",
    "        points: input points data, [Batch/ Blocks, Num Points, Num Features]\n",
    "        idx: sample index data, [Batch/ Blocks, New Num Points]\n",
    "    Return:\n",
    "        new_points: indexed points data, [Batches/ Blocks, New Num Points, Num Features]\n",
    "    \"\"\"\n",
    "    device = points.device\n",
    "    B = points.shape[0] # B is number of batches/ blocks\n",
    "    # Defining views/ shapes for the re-indexing\n",
    "    view_shape = list(idx.shape)\n",
    "    view_shape[1:] = [1] * (len(view_shape) - 1)\n",
    "    repeat_shape = list(idx.shape)\n",
    "    repeat_shape[0] = 1\n",
    "    # Batch/ Block indexing for input points according to previously defined views/ shapes\n",
    "    batch_indices = torch.arange(B, dtype=torch.long).to(device).view(view_shape).repeat(repeat_shape)\n",
    "    # Picking corresponding points from input points\n",
    "    new_points = points[batch_indices, idx, :]\n",
    "    \n",
    "    # Return reindexed points according to batch/ block index and New Num Points\n",
    "    return new_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testable Hypotheses\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, since the error seems to arise spontaneously at almost random iterations (or better said, to me random iterations), here you can find some ideas for what has been going sideways:<br>\n",
    "- batch/block number/index does not match\n",
    "- indices and points are on different devices \n",
    "- more will follow..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights from Debugging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I will shortly list the central insights from debugging the old version of the index_points function, as they might help when trying to design the new self-scripted version, or when adjusting the traditional formulation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After careful testing and adjsuting I found out, that it was an index issue, but most likely connected to the problem, that with the respective setting the model did not find enough points around centroids with the given radius. After increasing the radius and giving the model the opportunity to find enough sampels around centroids and also samples within the input point cloud, the problem is not apparent anymore. So this is important to be kept in mind. Nevertheless, it would be sueful to re-write this function for now, so that at least the data feed-in is constant and we are actually overtraining on one sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, as the funcitonality was proper before I learned that it is not the main funcitonality of the function which is an issue, but one has to keep an eye on the amount of points, the block size adn the radius to make sure the model does find enough centroids and sampels around the centroids to not run into an indexing issue, which unfortunately showcases itself in the less specific error mentioned above. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After taking a look at the testable hypotheses, and also trying to evaluate those accordingly, in the following you will find the proposed solutions and their results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Writing own re-indexing function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the logic of it should be rather straightforward, my first initial thought is to re-write the entire function according to my own understanding of its functionality, then subsequent debugging might also be easier. A first draft of a version can be found below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_points(points, idx):\n",
    "    \"\"\"\n",
    "    Indexing points according to new group index.\n",
    "    \n",
    "    Input:\n",
    "        points: input points data, [Batch/ Blocks, Num Points, Num Features]\n",
    "        idx: sample index data, [Batch/ Blocks, New Num Points]\n",
    "    Return:\n",
    "        new_points: indexed points data, [Batches/ Blocks, New Num Points, Num Features]\n",
    "    \"\"\"\n",
    "    \n",
    "    device = points.device\n",
    "    B = points.shape[0] # B is number of batches/ blocks\n",
    "    \n",
    "    # Check for index shape\n",
    "    if idx.shape[0] < B:\n",
    "        print(f\"Batch number lower for indeces. Should be {B}, but is {idx.shape[0]}\")\n",
    "    elif idx.shape[0] > B:\n",
    "        print(f\"Batch number higher for indeces. Should be {B}, but is {idx.shape[0]}\")\n",
    "        \n",
    "    # Defining shapes in respective dimension to be indexed\n",
    "    #! This does not work as you are iamgining!! Instead both pointers point to the same object, which is not what we want\n",
    "    batch_shape = sample_shape = list(idx.shape)\n",
    "    batch_shape[1:] = sample_shape[0] = 1\n",
    "    \n",
    "    # Creating batch indices by indexing according to the shapes\n",
    "    batch_indices = torch.arange(B, dtyp=torch.long).to(device).view(batch_shape).repeat(sample_shape)\n",
    "    \n",
    "    # Selecting corresponding point from input points\n",
    "    new_points = points[batch_indices, idx, :]\n",
    "    \n",
    "    # Return reindexed points according to batch/ block index\n",
    "    return new_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing-Cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below here you can find a collection of some simple cells in which I might test some basic hypotheses, but mostly about playing round with some single effects before piecing them together. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Slicing and selecting from a multidimensional tensor "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing that I found confusing in the old version was the selection of the points from the input points to that function:<br>\n",
    "*points[batch_indices, idx, :]*<br>\n",
    "The reason I find it confusing is that the batch_indices is a 2D tensor of the shape [batches x num_points_NEW]. Therefore, we will have a short investigation into the slection of points from another tensor in this way. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Slicing and selecting with simplified dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting to slice and dice with the actual dimensions, I think it is the easiest to walk through it all in a simplified setting, therefore we will reduce the amount of rows and columns significantly to check for the working of the operations we are undertaking. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Print check for sizes and batch_indices creation ------\n",
      "torch.Size([2, 2])\n",
      "torch.Size([2])\n",
      "tensor([0, 0])\n",
      "tensor([1, 1])\n",
      "-----------\n",
      "----- Print check for selected points -----\n",
      "Sizes and Shapes:\n",
      "points shape: torch.Size([2, 4, 3])\n",
      "new_points shape: torch.Size([2, 2, 3])\n",
      "-----------\n",
      "Tensor values:\n",
      "points tensor: tensor([[[ 0,  1,  2],\n",
      "         [ 3,  4,  5],\n",
      "         [ 6,  7,  8],\n",
      "         [ 9, 10, 11]],\n",
      "\n",
      "        [[12, 13, 14],\n",
      "         [15, 16, 17],\n",
      "         [18, 19, 20],\n",
      "         [21, 22, 23]]])\n",
      "new_points tensor: tensor([[[ 3,  4,  5],\n",
      "         [ 9, 10, 11]],\n",
      "\n",
      "        [[12, 13, 14],\n",
      "         [18, 19, 20]]])\n"
     ]
    }
   ],
   "source": [
    "# Creation of simplified tensor denoting points and index\n",
    "points = torch.arange(start=0, end=24, step=1, dtype=torch.long).reshape(2,4,3)\n",
    "idx = torch.tensor([[1,3], [0,2]])\n",
    "# Creation of simplified shapes for re-indexing\n",
    "view_shape = [2, 1]\n",
    "repeat_shape = [1, 2]\n",
    "# Creation of batch indices\n",
    "batch_indices = torch.arange(2, dtype=torch.long).view(view_shape).repeat(repeat_shape)\n",
    "\n",
    "# Print check \n",
    "print(\"------ Print check for sizes and batch_indices creation ------\")\n",
    "print(batch_indices.shape)\n",
    "print(batch_indices[0].shape)\n",
    "print(batch_indices[0])\n",
    "print(batch_indices[1])\n",
    "print(\"-----------\")\n",
    "\n",
    "# Slicing/ Selecting points with batch_indices\n",
    "new_points = points[batch_indices, idx, :]\n",
    "\n",
    "# Print Check\n",
    "print(\"----- Print check for selected points -----\")\n",
    "print(\"Sizes and Shapes:\")\n",
    "print(f\"points shape: {points.shape}\")\n",
    "print(f\"new_points shape: {new_points.shape}\")\n",
    "print(\"-----------\")\n",
    "print(\"Tensor values:\")\n",
    "print(f\"points tensor: {points}\")\n",
    "print(f\"new_points tensor: {new_points}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the main insight is, that the slicing/ selecting of the tensor does work as it should and it is a valid and valuable way of using the slicing or selection of points fromt he other tensor. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Slicing and selecting in network setting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After now trying the slicing on a simplified version, we now want to simulate a real tensor of the actual (or at least a possible) size within the network, to check for its funcitonality. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Checking new points created ------\n",
      "new_points shape: torch.Size([8, 1024, 3])\n"
     ]
    }
   ],
   "source": [
    "# Creation of an input tensor of the size of input points\n",
    "points = torch.arange(start=0, end=98304, step=1, dtype=torch.long).reshape(8, 4096,3)\n",
    "idx = torch.randint(low=0, high=4096, size=(8, 1024))\n",
    "# Creation of shapes used for re-indexing\n",
    "B = 8\n",
    "view_shape = [8,1]\n",
    "repeat_shape = [1,1024]\n",
    "batch_indices = torch.arange(B, dtype=torch.long).view(view_shape).repeat(repeat_shape)\n",
    "new_points = points[batch_indices, idx, :]\n",
    "\n",
    "# Print check\n",
    "print(\"------ Checking new points created ------\")\n",
    "print(f\"new_points shape: {new_points.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bottom line, after the investigation found that the indexing error does not arise from the function but rather from the sampling of the input point cloud, that is happening in the network. Therefore, not the biggest changes to the actual functionality are going to be inserted, but rather some changes to finally standardize the selection of points within the actual block of the batch. Because of the random selection of points in the getitem method of the dataset class, the point selectiopn and data input to the network was not uniform during the training, so that's why the network most likely had some trouble learning and also why the shapes adn sizes differed and at some point eventually lead to the idnexing error described above."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pointnet2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
